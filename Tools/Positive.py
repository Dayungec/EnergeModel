import pandas as pd
from typing import Tuple
import numpy as np
import os

from matplotlib import pyplot as plt
from sklearn.metrics import auc  # ä¿ç•™aucç”¨äºè®¡ç®—æ›²çº¿ä¸‹é¢ç§¯

# ----------------------------
# 1. æ•°æ®åŠ è½½ï¼ˆå¢åŠ æµ‹è¯•æ•°æ®åŠ è½½ï¼‰
# ----------------------------
from EnergeModel.Tools import Config, DataReader
from EnergeModel.Tools.ShapAnalyse import ShapAnalyse

def load_data(pos_path: str, bg_path: str, test_path: str = None) -> Tuple[
    pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, list]:
    """åŠ è½½æ­£è´Ÿæ ·æœ¬æ•°æ®ã€èƒŒæ™¯æ ·æœ¬æ•°æ®å’Œæµ‹è¯•æ•°æ®"""
    df_pos = DataReader.load_data(pos_path)
    pos_columns_order = df_pos.columns.tolist()

    df_bg = DataReader.load_data(bg_path)

    # éªŒè¯èƒŒæ™¯æ•°æ®æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„åˆ—
    missing_in_bg = set(pos_columns_order) - set(df_bg.columns)
    if missing_in_bg:
        raise ValueError(f"èƒŒæ™¯æ•°æ®ç¼ºå¤±ä»¥ä¸‹åˆ—: {missing_in_bg}")

    df_bg = df_bg.reindex(columns=pos_columns_order)

    df_test = None
    if test_path and os.path.exists(test_path):
        df_test = DataReader.load_data(test_path)

        # éªŒè¯æµ‹è¯•æ•°æ®æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„åˆ—
        missing_in_test = set(pos_columns_order) - set(df_test.columns)
        if missing_in_test:
            print(f"è­¦å‘Š: æµ‹è¯•æ•°æ®ç¼ºå¤±ä»¥ä¸‹åˆ—ï¼Œå°†å¡«å……NaN: {missing_in_test}")

        df_test = df_test.reindex(columns=pos_columns_order)
        df_test = df_test.astype(np.float32)

    df_pos = df_pos.astype(np.float32)
    df_bg = df_bg.astype(np.float32)

    return df_pos, df_bg, df_test, pos_columns_order


def calculate_pq_curve(positive_probs, background_probs, n_thresholds=100):
    """
    æ­£ç¡®è®¡ç®—P-Qæ›²çº¿å’ŒAD-AUCé¢ç§¯
    P = æ­£æ ·æœ¬ä¸­é¢„æµ‹ä¸ºæ­£çš„æ¯”ä¾‹
    Q = èƒŒæ™¯æ ·æœ¬ä¸­é¢„æµ‹ä¸ºæ­£çš„æ¯”ä¾‹
    """
    # ç”Ÿæˆé˜ˆå€¼ä»0åˆ°1ï¼ˆä»é«˜åˆ°ä½ï¼‰
    thresholds = np.linspace(1, 0, n_thresholds)  # ä»1åˆ°0ï¼Œç¡®ä¿Qä»0åˆ°1
    p_values = []  # é¢„æµ‹ç²¾åº¦
    q_values = []  # é¢„æµ‹å¯†åº¦

    for t in thresholds:
        # è®¡ç®—é¢„æµ‹ç²¾åº¦Pï¼šæ­£æ ·æœ¬ä¸­é¢„æµ‹ä¸ºæ­£çš„æ¯”ä¾‹
        pos_predicted = (positive_probs >= t).astype(int)
        p = np.mean(pos_predicted) if len(positive_probs) > 0 else 0

        # è®¡ç®—é¢„æµ‹å¯†åº¦Qï¼šèƒŒæ™¯æ ·æœ¬ä¸­é¢„æµ‹ä¸ºæ­£çš„æ¯”ä¾‹
        bg_predicted = (background_probs >= t).astype(int)
        q = np.mean(bg_predicted) if len(background_probs) > 0 else 0

        p_values.append(p)
        q_values.append(q)

    # å°†åˆ—è¡¨è½¬æ¢ä¸ºnumpyæ•°ç»„
    q_values = np.array(q_values)
    p_values = np.array(p_values)

    # è®¡ç®—æ›²çº¿ä¸‹é¢ç§¯ï¼ˆä½¿ç”¨æ¢¯å½¢ç§¯åˆ†ï¼‰
    # æ³¨æ„ï¼šQæ˜¯æ¨ªè½´ï¼ŒPæ˜¯çºµè½´
    ad_auc = auc(q_values, p_values)

    return thresholds, q_values, p_values, ad_auc

# ä½¿ç”¨åŸºäºå®é™…åˆ†å¸ƒçš„ç™¾åˆ†ä½æ•°é˜ˆå€¼
def get_realistic_thresholds(df_bg):
    """æ ¹æ®å®é™…æ¦‚ç‡åˆ†å¸ƒè®¾ç½®åˆç†é˜ˆå€¼"""

    pos_probs = df_bg["åŸå§‹æ¦‚ç‡"].values
    pos_sorted = np.sort(pos_probs)[::-1]  # é™åº

    # ä½¿ç”¨ç™¾åˆ†ä½æ•°ï¼Œç¡®ä¿æ¯ä¸ªåŒºåŸŸéƒ½æœ‰åˆç†çš„ç¾å®³ç‚¹åˆ†å¸ƒ
    thresholds = [
        np.percentile(pos_sorted, 80),  # é«˜é£é™©åŒº
        np.percentile(pos_sorted, 60),  # ä¸­é«˜é£é™©åŒº
        np.percentile(pos_sorted, 40),  # ä¸­é£é™©åŒº
        np.percentile(pos_sorted, 20),  # ä¸­ä½é£é™©åŒº
    ]

    print(f"å®é™…ä½¿ç”¨çš„é˜ˆå€¼: {[f'{t:.3f}' for t in thresholds]}")
    return thresholds

def calculate_risk_zones(model, df_bg, df_pos, feature_names,
                                  thresholds=[0.8, 0.6, 0.4,0.2]):
    """ç»“åˆå›ºå®šé˜ˆå€¼å’Œç¾å®³ç‚¹æ¯”ä¾‹çš„é£é™©åŒºåŸŸåˆ’åˆ†"""

    pos_path = Config.BASE_DIR + "positive_all.xlsx"
    df_pos = DataReader.load_data(pos_path)

    # é¢„æµ‹æ¦‚ç‡
    X_bg = df_bg[feature_names].values.astype(np.float32)
    df_bg["é¢„æµ‹æ¦‚ç‡"] = model.predict_proba(X_bg)

    X_pos = df_pos[feature_names].values.astype(np.float32)
    df_pos["é¢„æµ‹æ¦‚ç‡"] = model.predict_proba(X_pos)

    pos_probs = df_pos["é¢„æµ‹æ¦‚ç‡"].values

    # ç¡®ä¿é˜ˆå€¼é€’å‡
    for i in range(1, len(thresholds)):
        if thresholds[i] > thresholds[i - 1]:
            thresholds[i] = thresholds[i - 1] - 0.001

    # å®šä¹‰é£é™©åŒºåŸŸ
    risk_names = ['é«˜é£é™©åŒº', 'ä¸­é«˜é£é™©åŒº', 'ä¸­é£é™©åŒº', 'ä¸­ä½é£é™©åŒº', 'ä½é£é™©åŒº']

    risk_results = {}

    # è®¡ç®—å‰4ä¸ªé£é™©åŒºåŸŸ
    for i in range(len(risk_names) - 1):
        risk_name = risk_names[i]

        if i == 0:
            lower_threshold = thresholds[0]
            upper_threshold = 1.0
            pos_in_zone = df_pos[df_pos["é¢„æµ‹æ¦‚ç‡"] >= lower_threshold]
            bg_in_zone = df_bg[df_bg["é¢„æµ‹æ¦‚ç‡"] >= lower_threshold]
        else:
            lower_threshold = thresholds[i]
            upper_threshold = thresholds[i - 1]
            pos_in_zone = df_pos[(df_pos["é¢„æµ‹æ¦‚ç‡"] >= lower_threshold) &
                                 (df_pos["é¢„æµ‹æ¦‚ç‡"] < upper_threshold)]
            bg_in_zone = df_bg[(df_bg["é¢„æµ‹æ¦‚ç‡"] >= lower_threshold) &
                               (df_bg["é¢„æµ‹æ¦‚ç‡"] < upper_threshold)]

        # è®¡ç®—æ¯”ä¾‹
        n_pos_in_zone = len(pos_in_zone)
        n_bg_in_zone = len(bg_in_zone)
        total_pos = len(df_pos)
        total_bg = len(df_bg)

        disaster_ratio = n_pos_in_zone / total_pos if total_pos > 0 else 0
        bg_ratio = n_bg_in_zone / total_bg if total_bg > 0 else 0

        risk_results[risk_name] = {
            'é˜ˆå€¼èŒƒå›´': f"{lower_threshold:.4f} - {upper_threshold:.4f}",
            'ä¸‹é™é˜ˆå€¼': lower_threshold,
            'ä¸Šé™é˜ˆå€¼': upper_threshold,
            'ç¾å®³ç‚¹æ•°é‡': n_pos_in_zone,
            'ç¾å®³ç‚¹æ¯”ä¾‹': disaster_ratio,
            'èƒŒæ™¯æ ·æœ¬æ•°é‡': n_bg_in_zone,
            'èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹': bg_ratio
        }

    # è®¡ç®—æä½é£é™©åŒº
    risk_name = 'æä½é£é™©åŒº'
    lower_threshold = 0.0
    upper_threshold = thresholds[-1]

    pos_in_zone = df_pos[df_pos["é¢„æµ‹æ¦‚ç‡"] < upper_threshold]
    bg_in_zone = df_bg[df_bg["é¢„æµ‹æ¦‚ç‡"] < upper_threshold]

    n_pos_in_zone = len(pos_in_zone)
    n_bg_in_zone = len(bg_in_zone)

    disaster_ratio = n_pos_in_zone / total_pos if total_pos > 0 else 0
    bg_ratio = n_bg_in_zone / total_bg if total_bg > 0 else 0

    risk_results[risk_name] = {
        'é˜ˆå€¼èŒƒå›´': f"{lower_threshold:.4f} - {upper_threshold:.4f}",
        'ä¸‹é™é˜ˆå€¼': lower_threshold,
        'ä¸Šé™é˜ˆå€¼': upper_threshold,
        'ç¾å®³ç‚¹æ•°é‡': n_pos_in_zone,
        'ç¾å®³ç‚¹æ¯”ä¾‹': disaster_ratio,
        'èƒŒæ™¯æ ·æœ¬æ•°é‡': n_bg_in_zone,
        'èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹': bg_ratio
    }

    return risk_results, df_bg, df_pos

def evaluate_test_set(model, df_test,df_bg, feature_names):
    if df_test is None:
        return None

    # æå–ç‰¹å¾æ•°æ®
    X_test = df_test[feature_names].values.astype(np.float32)
    y_test = np.ones(len(X_test))

    # è·å–é¢„æµ‹æ¦‚ç‡
    y_pred_proba = model.predict_proba(X_test)
    y_pred = (y_pred_proba >= 0.5).astype(int)

    positive_probs = df_test["åŸå§‹æ¦‚ç‡"].values
    background_probs = df_bg["åŸå§‹æ¦‚ç‡"].values
    # è®¡ç®—P-Qæ›²çº¿
    _, _, _, ad_auc = calculate_pq_curve(
        positive_probs, background_probs
    )

    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = np.mean(y_pred == y_test)  # ç­‰ä»·äºaccuracy_score

    return {
        "ad_auc_score_test": ad_auc,
        'test_accuracy': float(accuracy),  # è½¬æ¢ä¸ºPythonåŸç”Ÿfloatç±»å‹
        'test_size': len(X_test)
    }

def train_and_evaluate(
        model,
        pos_path: str,
        bg_path: str,
        test_path: str = None,  # æ–°å¢æµ‹è¯•é›†è·¯å¾„
        output_dir: str = "results"
) -> dict:
    os.makedirs(output_dir, exist_ok=True)

    # æ•°æ®åŠ è½½ï¼ˆåŒ…å«æµ‹è¯•æ•°æ®ï¼‰
    df_pos, df_bg, df_test, feature_names = load_data(pos_path, bg_path, test_path)

    # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºè®­ç»ƒ
    X_pos = df_pos.values.astype(np.float32)
    X_bg = df_bg.values.astype(np.float32)
    X_test = df_test.values.astype(np.float32)

    print(f"æ­£æ ·æœ¬æ•°é‡: {len(X_pos)}")
    print(f"èƒŒæ™¯æ ·æœ¬æ•°é‡: {len(df_bg)}")
    if df_test is not None:
        print(f"æµ‹è¯•æ ·æœ¬æ•°é‡: {len(df_test)}")
    print(f"ç‰¹å¾ç»´åº¦: {X_pos.shape[1]}")
    print(f"ç‰¹å¾å: {feature_names}")

    # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    model.fit(X_pos,X_bg, feature_names)

    # è¯„ä¼°æ¨¡å‹ï¼ˆå¢åŠ æµ‹è¯•é›†è¯„ä¼°ï¼‰
    results = evaluate_model(model, X_pos, X_bg,X_test,df_pos, df_bg, df_test, feature_names, output_dir)

    if os.path.exists(Config.BASE_DIR + "test2.xlsx"):
        df_test2 = DataReader.load_data(Config.BASE_DIR + "test2.xlsx")
        X_test2 = df_test2.values.astype(np.float32)
        df_test2["åŸå§‹æ¦‚ç‡"] = model.predict_proba(X_test2)
        df_test2.to_excel(f"{output_dir}/test2_prob.xlsx", index=False)

    return results


def evaluate_model(
        model,
        X_pos: np.ndarray,
        X_bg: np.ndarray,
        X_test: np.ndarray,
        df_pos: pd.DataFrame,
        df_bg: pd.DataFrame,
        df_test: pd.DataFrame,  # æ–°å¢æµ‹è¯•é›†
        feature_names: list,
        output_dir: str,
        calcu_zone=True
) -> dict:
    """æ¨¡å‹è¯„ä¼°ï¼ˆå¢åŠ æµ‹è¯•é›†è¯„ä¼°ï¼‰"""
    # é¢„æµ‹æ¦‚ç‡
    df_pos["åŸå§‹æ¦‚ç‡"] = model.predict_proba(X_pos)
    df_bg["åŸå§‹æ¦‚ç‡"] = model.predict_proba(X_bg)
    df_test["åŸå§‹æ¦‚ç‡"] = model.predict_proba(X_test)

    # è®¡ç®—è®­ç»ƒé›†AUC
    positive_probs = df_pos["åŸå§‹æ¦‚ç‡"].values
    background_probs = df_bg["åŸå§‹æ¦‚ç‡"].values
    # è®¡ç®—P-Qæ›²çº¿
    thresholds, q_values, p_values, ad_auc = calculate_pq_curve(
        positive_probs, background_probs
    )

    print(f"ğŸ“ˆ P-Qæ›²çº¿ç»“æœ:")
    print(f"   - AD-AUCé¢ç§¯: {ad_auc:.4f}")
    print(f"   - På€¼èŒƒå›´: {p_values.min():.3f} ~ {p_values.max():.3f}")
    print(f"   - Qå€¼èŒƒå›´: {q_values.min():.3f} ~ {q_values.max():.3f}")

    # ä¿å­˜P-Qæ›²çº¿æ•°æ®åˆ°Excel
    pq_data = pd.DataFrame({
        'Threshold': thresholds,
        'Prediction_Density_Q': q_values,
        'Prediction_Accuracy_P': p_values
    })
    pq_data.to_excel(f"{output_dir}/pq_curve_data.xlsx", index=False)


    y_pred = (df_pos["åŸå§‹æ¦‚ç‡"] >= 0.5).astype(int)
    y_test = np.ones(len(df_pos["åŸå§‹æ¦‚ç‡"]))
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = np.mean(y_pred == y_test)
    m_pred = (df_bg["åŸå§‹æ¦‚ç‡"] >= 0.5).astype(int)
    m_test = np.ones(len(df_bg["åŸå§‹æ¦‚ç‡"]))
    density=np.mean(m_pred == m_test)

    if calcu_zone:
        thresholds=get_realistic_thresholds(df_bg)
        # åˆ’åˆ†é£é™©åŒºåŸŸ
        risk_results, df_bg_with_prob, df_pos_with_prob = calculate_risk_zones(model, df_bg, df_pos, feature_names,thresholds)

    # ç‰¹å¾é‡è¦æ€§
    feature_importance = model.get_feature_importance()
    feature_importance_df =None
    if feature_importance is not None:
       feature_importance_df = pd.DataFrame({
          'feature': feature_names,
          'importance': feature_importance
        }).sort_values('importance', ascending=False)

    # æµ‹è¯•é›†è¯„ä¼°ï¼ˆæ–°å¢ï¼‰
    test_metrics = evaluate_test_set(model, df_test,df_bg, feature_names)

    # ä¿å­˜ç»“æœ
    if calcu_zone:
        df_pos_with_prob.to_excel(f"{output_dir}/positive_with_prob.xlsx", index=False)
        df_bg_with_prob.to_excel(f"{output_dir}/background_with_prob.xlsx", index=False)
    if feature_importance_df is not None:
        feature_importance_df.to_excel(f"{output_dir}/feature_importance.xlsx", index=False)

    # ä¿å­˜æµ‹è¯•é›†ç»“æœ
    if calcu_zone:
        if df_test is not None:
            df_test_result = df_test.copy()
            X_test = df_test[feature_names].values.astype(np.float32)
            df_test_result["é¢„æµ‹æ¦‚ç‡"] = model.predict_proba(X_test)
            df_test_result.to_excel(f"{output_dir}/test_set_predictions.xlsx", index=False)

    # ä¿å­˜é£é™©åŒºåŸŸç»“æœ
    if calcu_zone:
        risk_df = pd.DataFrame(risk_results).T
        risk_df.to_excel(f"{output_dir}/risk_zone_analysis.xlsx")

    # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
    if calcu_zone:
        metrics = {
            "ad_auc_score": ad_auc,
            "pos_prob_mean": df_pos["åŸå§‹æ¦‚ç‡"].mean(),
            "bg_prob_mean": df_bg["åŸå§‹æ¦‚ç‡"].mean(),
            "pos_prob_std": df_pos["åŸå§‹æ¦‚ç‡"].std(),
            "bg_prob_std": df_bg["åŸå§‹æ¦‚ç‡"].std(),
            "pos_median": np.median(df_pos["åŸå§‹æ¦‚ç‡"]),
            "bg_median": np.median(df_bg["åŸå§‹æ¦‚ç‡"]),
            'train_accuracy': float(accuracy),
            'train_size': len(df_pos["åŸå§‹æ¦‚ç‡"]),
            'train_density': float(density),
            "feature_importance": feature_importance_df,
            "risk_zones": risk_results,
        }
    else:
        metrics = {
            "ad_auc_score": ad_auc,
            "pos_prob_mean": df_pos["åŸå§‹æ¦‚ç‡"].mean(),
            "bg_prob_mean": df_bg["åŸå§‹æ¦‚ç‡"].mean(),
            "pos_prob_std": df_pos["åŸå§‹æ¦‚ç‡"].std(),
            "bg_prob_std": df_bg["åŸå§‹æ¦‚ç‡"].std(),
            "pos_median": np.median(df_pos["åŸå§‹æ¦‚ç‡"]),
            "bg_median": np.median(df_bg["åŸå§‹æ¦‚ç‡"]),
            'train_accuracy': float(accuracy),
            'train_size': len(df_pos["åŸå§‹æ¦‚ç‡"]),
            'train_density': float(density),
            "feature_importance": feature_importance_df,
        }
    # åˆå¹¶æµ‹è¯•é›†æŒ‡æ ‡
    if test_metrics:
        metrics.update(test_metrics)
    if Config.SHAP_ANA == 1 :
        # SHAPåˆ†æ
        try:
            shap_analyzer = ShapAnalyse(model, feature_names)
            shap_analyzer.Analyse(df_pos, df_bg, feature_importance_df, metrics, output_dir)
        except Exception as e:
            print(f"SHAPåˆ†æè·³è¿‡: {e}")

    # å¯è§†åŒ–ï¼ˆå¢åŠ æµ‹è¯•é›†ç»“æœå±•ç¤ºï¼‰
    if calcu_zone:
        create_visualizations(model,df_pos, df_bg, metrics, feature_importance_df, risk_results, output_dir, df_test)
    return metrics


# ----------------------------
# 7. å¯è§†åŒ–å‡½æ•°ï¼ˆå¢åŠ æµ‹è¯•é›†å±•ç¤ºï¼‰
# ----------------------------
def create_visualizations(model,df_pos,df_bg, metrics, feature_importance_df, risk_results, output_dir,
                                  df_test=None):
    """åˆ›å»ºPUç‰ˆæœ¬çš„å¯è§†åŒ–ï¼ˆå¢åŠ æµ‹è¯•é›†ç»“æœï¼‰"""
    if df_test is not None:
        plt.figure(figsize=(25, 15))
        n_subplots = 7
    else:
        plt.figure(figsize=(20, 15))
        n_subplots = 6

    # 1. æ¦‚ç‡åˆ†å¸ƒå›¾
    plt.subplot(2, 4, 1)
    plt.hist(df_pos["åŸå§‹æ¦‚ç‡"], bins=50, alpha=0.5, label=f"è®­ç»ƒæ­£æ ·æœ¬ (n={len(df_pos)})", density=True)
    plt.hist(df_bg["åŸå§‹æ¦‚ç‡"], bins=50, alpha=0.5, label=f"è®­ç»ƒèƒŒæ™¯æ ·æœ¬ (n={len(df_bg)})", density=True)


    # æ·»åŠ é£é™©åŒºåŸŸé˜ˆå€¼çº¿
    colors = ['red', 'orange', 'yellow', 'lightblue', 'blue']
    risk_names = list(risk_results.keys())

    for i, risk_name in enumerate(risk_names):
        lower_threshold = risk_results[risk_name]['ä¸‹é™é˜ˆå€¼']
        plt.axvline(lower_threshold, color=colors[i], linestyle='--', alpha=0.7, label=f'{risk_name}ä¸‹é™')

    plt.xlabel("é¢„æµ‹æ¦‚ç‡", fontsize=12)
    plt.ylabel("å¯†åº¦", fontsize=12)
    title = f"æ¦‚ç‡åˆ†å¸ƒ (AUC={metrics['ad_auc_score']:.3f})"
    plt.title(title, fontsize=14)
    plt.legend(fontsize=8)
    plt.grid(True, alpha=0.3)


    # 2. ç‰¹å¾é‡è¦æ€§
    if feature_importance_df is not None:
        plt.subplot(2, 4, 2)
        top_features = feature_importance_df.head(15)
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('ç‰¹å¾é‡è¦æ€§')
        plt.title('PU Topç‰¹å¾é‡è¦æ€§')
        plt.gca().invert_yaxis()

        # 3. P-Qæ›²çº¿ï¼ˆä¸æ ‡è®°æœ€ä¼˜ç‚¹ï¼‰
    plt.subplot(2, 4, 3)

    # é‡æ–°è®¡ç®—P-Qæ›²çº¿æ•°æ®
    positive_probs = df_pos["åŸå§‹æ¦‚ç‡"].values
    background_probs = df_bg["åŸå§‹æ¦‚ç‡"].values
    thresholds, q_values, p_values, ad_auc = calculate_pq_curve(positive_probs, background_probs)

    plt.plot(q_values, p_values, 'b-', linewidth=2, label=f'P-Q Curve (AD-AUC = {ad_auc:.4f})')
    plt.plot([0, 1], [0, 1], 'r--', alpha=0.5, label='éšæœºåŸºçº¿')

    plt.xlabel('é¢„æµ‹å¯†åº¦ (Q)', fontsize=12)
    plt.ylabel('é¢„æµ‹ç²¾åº¦ (P)', fontsize=12)
    plt.title('P-Qæ›²çº¿: ç²¾åº¦ vs å¯†åº¦', fontsize=14)
    plt.legend(loc='lower left')
    plt.grid(True, alpha=0.3)

    # æ·»åŠ è§£é‡Šæ€§æ–‡æœ¬ï¼ˆä¸æ¶‰åŠæœ€ä¼˜é˜ˆå€¼ï¼‰
    plt.text(0.05, 0.95, 'å·¦ä¸Šè§’: é«˜ç²¾åº¦ä½å¯†åº¦\nå³ä¸‹è§’: ä½ç²¾åº¦é«˜å¯†åº¦',
             transform=plt.gca().transAxes, fontsize=10,
             bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

    # 4. é£é™©åŒºåŸŸç¾å®³ç‚¹æ¯”ä¾‹
    plt.subplot(2, 4, 4)
    disaster_ratios = [risk_results[name]['ç¾å®³ç‚¹æ¯”ä¾‹'] for name in risk_names]
    bars = plt.bar(risk_names, disaster_ratios, color=colors)
    plt.ylabel('ç¾å®³ç‚¹æ¯”ä¾‹')
    plt.title('å„é£é™©åŒºåŸŸç¾å®³ç‚¹æ¯”ä¾‹')
    plt.xticks(rotation=45)
    for bar, ratio in zip(bars, disaster_ratios):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{ratio:.1%}', ha='center', va='bottom')

    # 6. é£é™©åŒºåŸŸåˆ†å¸ƒé¥¼å›¾
    plt.subplot(2, 4, 6)
    bg_ratios = [max(risk_results[name]['èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹'], 0) for name in risk_names]
    valid_indices = [i for i, ratio in enumerate(bg_ratios) if ratio > 0]
    if valid_indices:
        valid_ratios = [bg_ratios[i] for i in valid_indices]
        valid_labels = [risk_names[i] for i in valid_indices]
        valid_colors = [colors[i] for i in valid_indices]
        plt.pie(valid_ratios, labels=valid_labels, autopct='%1.1f%%', colors=valid_colors)
        plt.title('é£é™©åŒºåŸŸåˆ†å¸ƒæ¯”ä¾‹')
    else:
        plt.text(0.5, 0.5, 'æ— æœ‰æ•ˆæ•°æ®', ha='center', va='center', transform=plt.gca().transAxes)
        plt.title('é£é™©åŒºåŸŸåˆ†å¸ƒæ¯”ä¾‹ï¼ˆæ— æ•°æ®ï¼‰')

    # 7. æ¦‚ç‡ç®±çº¿å›¾
    plt.subplot(2, 4, 7)
    prob_data = [df_pos["åŸå§‹æ¦‚ç‡"], df_bg["åŸå§‹æ¦‚ç‡"]]
    if df_test is not None and 'é¢„æµ‹æ¦‚ç‡' in df_test.columns:
        test_pos_probs = df_test[df_test.iloc[:, -1] == 1]["é¢„æµ‹æ¦‚ç‡"] if len(df_test[df_test.iloc[:, -1] == 1]) > 0 else []
        test_neg_probs = df_test[df_test.iloc[:, -1] == 0]["é¢„æµ‹æ¦‚ç‡"] if len(df_test[df_test.iloc[:, -1] == 0]) > 0 else []
        if len(test_pos_probs) > 0 and len(test_neg_probs) > 0:
            prob_data.extend([test_pos_probs, test_neg_probs])
            labels = ['è®­ç»ƒæ­£æ ·æœ¬', 'è®­ç»ƒèƒŒæ™¯æ ·æœ¬', 'æµ‹è¯•æ­£æ ·æœ¬', 'æµ‹è¯•è´Ÿæ ·æœ¬']
        else:
            labels = ['è®­ç»ƒæ­£æ ·æœ¬', 'è®­ç»ƒèƒŒæ™¯æ ·æœ¬']
    else:
        labels = ['è®­ç»ƒæ­£æ ·æœ¬', 'è®­ç»ƒèƒŒæ™¯æ ·æœ¬']

    plt.boxplot(prob_data, labels=labels)
    plt.ylabel('æ˜“å‘æ€§æ¦‚ç‡')
    plt.title('æ¦‚ç‡åˆ†å¸ƒç®±çº¿å›¾')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f"{output_dir}/comprehensive_analysis.png", dpi=300, bbox_inches='tight')
    plt.close()

