import time
import numpy as np
import pandas as pd
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import torch
import os
import warnings
import Tools.Positive
from EnergeModel.Tools import Config, DataReader
from EnergeModel.Tools.RasterProcessor import RasterProcessor

plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


# ----------------------------
# 2. å•åˆ†ç±»SVMæ¨¡å‹ç±»
# ----------------------------
class OneClassSVMSusceptibilityModel:
    """
    å•åˆ†ç±»SVMæ¨¡å‹ï¼ˆä»…ä½¿ç”¨æ­£æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼‰
    é€‚ç”¨äºå¼‚å¸¸æ£€æµ‹å’Œæ–°é¢–æ€§æ£€æµ‹ä»»åŠ¡
    """

    def __init__(self, input_dim: int, random_state: int = 42):
        self.input_dim = input_dim
        self.random_state = random_state
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None

    def build_model(self, **ocsvm_params):
        """æ„å»ºå•åˆ†ç±»SVMæ¨¡å‹"""
        # å•åˆ†ç±»SVMçš„é»˜è®¤å‚æ•°
        default_params = {
            'nu': 0.1,  # å¼‚å¸¸å€¼æ¯”ä¾‹çš„ä¸Šç•Œ
            'kernel': 'rbf',  # æ ¸å‡½æ•°ç±»å‹
            'gamma': 'scale'
        }

        # æ›´æ–°ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°
        default_params.update(ocsvm_params)

        self.model = OneClassSVM(**default_params)
        return self.model

    def fit(self, X_train, X_val=None):
        """
        è®­ç»ƒæ¨¡å‹ - ä»…ä½¿ç”¨æ­£æ ·æœ¬
        å•åˆ†ç±»SVMåªéœ€è¦æ­£æ ·æœ¬è¿›è¡Œè®­ç»ƒ
        """
        # æ•°æ®æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)

        # å•åˆ†ç±»SVMè®­ç»ƒï¼ˆåªéœ€è¦æ­£æ ·æœ¬ï¼‰
        self.model.fit(X_train_scaled)

        if X_val is not None:
            # å¯¹äºå•åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—åœ¨éªŒè¯é›†ä¸Šçš„å¼‚å¸¸æ£€æµ‹æ€§èƒ½
            X_val_scaled = self.scaler.transform(X_val)
            # é¢„æµ‹ç»“æœï¼š+1è¡¨ç¤ºæ­£å¸¸æ ·æœ¬ï¼Œ-1è¡¨ç¤ºå¼‚å¸¸æ ·æœ¬
            val_pred = self.model.predict(X_val_scaled)
            # è®¡ç®—æ­£å¸¸æ ·æœ¬çš„æ¯”ä¾‹ï¼ˆå¯ä»¥ä½œä¸ºæ€§èƒ½å‚è€ƒï¼‰
            normal_ratio = np.sum(val_pred == 1) / len(val_pred)
            print(f"éªŒè¯é›†æ­£å¸¸æ ·æœ¬æ¯”ä¾‹: {normal_ratio:.4f}")

        return self.model

    def predict_proba(self, X):
        """
        é¢„æµ‹æ ·æœ¬ä¸ºæ­£å¸¸æ ·æœ¬çš„æ¦‚ç‡
        å°†OneClassSVMçš„å†³ç­–å‡½æ•°å€¼è½¬æ¢ä¸ºæ¦‚ç‡ä¼°è®¡
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")

        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.transform(X)

        # ä½¿ç”¨decision_functionè·å–åˆ°å†³ç­–è¾¹ç•Œçš„è·ç¦»
        # è·ç¦»è¶Šå¤§ï¼Œè¡¨ç¤ºè¶Šå¯èƒ½æ˜¯æ­£å¸¸æ ·æœ¬
        distances = self.model.decision_function(X_scaled)

        # å°†è·ç¦»è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆä½¿ç”¨sigmoidå‡½æ•°è¿›è¡Œæ ‡å‡†åŒ–ï¼‰
        # æ³¨æ„ï¼šè¿™åªæ˜¯è¿‘ä¼¼æ¦‚ç‡ï¼Œå•åˆ†ç±»SVMä¸ç›´æ¥æä¾›æ¦‚ç‡ä¼°è®¡
        max_distance = np.max(np.abs(distances))
        if max_distance > 0:
            normalized_distances = distances / (2 * max_distance) + 0.5
        else:
            normalized_distances = 0.5 * np.ones_like(distances)

        probs = np.clip(normalized_distances, 0.001, 0.999)
        return probs

    def predict(self, X):
        """é¢„æµ‹æ ·æœ¬æ ‡ç­¾ï¼š+1æ­£å¸¸ï¼Œ-1å¼‚å¸¸"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")

        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)

    def get_feature_importance(self):
        """è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆä»…é€‚ç”¨äºçº¿æ€§æ ¸ï¼‰"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")

        if self.model.kernel != 'linear':
            print("è­¦å‘Š: ç‰¹å¾é‡è¦æ€§ä»…é€‚ç”¨äºçº¿æ€§æ ¸One-Class SVM")
            return np.zeros(self.input_dim)

        return np.abs(self.model.coef_[0])


# ----------------------------
# 3. åŸºäºå•åˆ†ç±»SVMçš„æ˜“å‘æ€§è¯„ä»·æ¨¡å‹
# ----------------------------
class OneClassSVMModel:
    def __init__(self, input_dim: int, random_state: int = 42):
        self.input_dim = input_dim
        self.random_state = random_state
        self.ocsvm_model = OneClassSVMSusceptibilityModel(input_dim, random_state)
        self.feature_names = None

    def forward(self, x):
        """ä¸ºäº†ä¿æŒæ¥å£ä¸€è‡´"""
        pass

    def training_step(self, batch, batch_idx):
        """è®­ç»ƒæ­¥éª¤ - ä¸ºäº†ä¿æŒæ¥å£å…¼å®¹"""
        pass

    def configure_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½® - ä¸ºäº†ä¿æŒæ¥å£å…¼å®¹"""
        pass

    def __call__(self, X):
        """ä½¿æ¨¡å‹å¯¹è±¡å¯è¢«ç›´æ¥è°ƒç”¨"""
        return self.predict_proba(X)

    def predict_proba(self, x):
        """é¢„æµ‹æ¦‚ç‡"""
        if isinstance(x, torch.Tensor):
            x = x.numpy()
        return self.ocsvm_model.predict_proba(x)

    def fit(self, X_pos, X_bg,feature_names, **ocsvm_params):
        """
        è®­ç»ƒå•åˆ†ç±»SVMæ¨¡å‹ - åªéœ€è¦æ­£æ ·æœ¬
        ä¸ä¼ ç»ŸäºŒåˆ†ç±»æ–¹æ³•ä¸åŒï¼Œå•åˆ†ç±»æ–¹æ³•ä¸éœ€è¦è´Ÿæ ·æœ¬
        """
        self.feature_names = feature_names

        # å•åˆ†ç±»SVMåªéœ€è¦æ­£æ ·æœ¬è¿›è¡Œè®­ç»ƒ
        X_train = X_pos  # ä»…ä½¿ç”¨æ­£æ ·æœ¬

        # æ„å»ºå¹¶è®­ç»ƒæ¨¡å‹
        self.ocsvm_model.build_model(**ocsvm_params)
        self.ocsvm_model.fit(X_train)

        print(f"âœ… å•åˆ†ç±»SVMè®­ç»ƒå®Œæˆï¼Œä½¿ç”¨æ­£æ ·æœ¬æ•°é‡: {len(X_train)}")
        return self

    def get_feature_importance(self):
        return self.ocsvm_model.get_feature_importance()


# ----------------------------
# ä¸»ç¨‹åº
# ----------------------------
if __name__ == "__main__":
    start_time = time.time()

    # æ–‡ä»¶è·¯å¾„é…ç½® - ç§»é™¤äº†neg_path
    pos_path = Config.BASE_DIR + Config.POSITIVE+".xlsx"
    bg_path = Config.BASE_DIR + "mesh3000.xlsx"  # èƒŒæ™¯æ ·æœ¬ç”¨äºè¯„ä¼°é¢„æµ‹å¯†åº¦
    test_path = Config.BASE_DIR + "test.xlsx"
    output_dir = "result/results_oneclass_svm"

    # è¿è¡Œè®­ç»ƒè¯„ä¼°æµç¨‹
    print("ğŸš€ å¼€å§‹è®­ç»ƒå•åˆ†ç±»SVMæ¨¡å‹...")
    df_pos = DataReader.load_data(pos_path)

    # åˆ›å»ºå•åˆ†ç±»SVMæ¨¡å‹
    model = OneClassSVMModel(input_dim=df_pos.shape[1])

    # ä¿®æ”¹è®­ç»ƒè¯„ä¼°è°ƒç”¨ï¼Œé€‚åº”å•åˆ†ç±»æ¨¡å¼
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è°ƒæ•´Tools.Regress.train_and_evaluateå‡½æ•°ä»¥æ”¯æŒå•åˆ†ç±»
    results = Tools.Positive.train_and_evaluate(
        model,
        pos_path=pos_path,
        bg_path=bg_path,
        test_path=test_path,  # ä¼ å…¥æµ‹è¯•é›†è·¯å¾„
        output_dir=output_dir
    )

    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\nâ­ å•åˆ†ç±»SVMæœ€ç»ˆè¯„ä¼°ç»“æœ â­")
    print(f"â— AD_AUCåˆ†æ•°: {results['ad_auc_score']:.4f}")
    print(f"â— é¢„æµ‹ç²¾åº¦: {results['train_accuracy']:.4f}")
    print(f"â— é¢„æµ‹å¯†åº¦: {results['train_density']:.4f}")
    print(
        f"â— æ­£æ ·æœ¬æ¦‚ç‡ç»Ÿè®¡ - å‡å€¼: {results['pos_prob_mean']:.3f} Â± {results['pos_prob_std']:.3f} | ä¸­ä½æ•°: {results['pos_median']:.3f}")

    # å•åˆ†ç±»æ¨¡å‹æ²¡æœ‰è´Ÿæ ·æœ¬ï¼Œè°ƒæ•´è¾“å‡º
    if 'bg_prob_mean' in results:
        print(
            f"â— èƒŒæ™¯æ ·æœ¬æ¦‚ç‡ç»Ÿè®¡ - å‡å€¼: {results['bg_prob_mean']:.3f} Â± {results['bg_prob_std']:.3f} | ä¸­ä½æ•°: {results['bg_median']:.3f}")

    # æ‰“å°æµ‹è¯•é›†ç»“æœ
    if 'test_accuracy' in results:
        print(f"\nğŸ§ª æµ‹è¯•é›†è¯„ä¼°ç»“æœï¼ˆçº¯ç¾å®³æ ·æœ¬ï¼‰:")
        print(f"â— AD_AUCåˆ†æ•°: {results['ad_auc_score_test']:.4f}")
        print(f"â— åˆ†ç±»å‡†ç¡®ç‡: {results['test_accuracy']:.2%}")
        print(f"â— æµ‹è¯•æ ·æœ¬æ•°: {results['test_size']}")

    print(f"\nğŸ“Š é£é™©åŒºåŸŸåˆ†æç»“æœ:")
    print("=" * 80)
    print(f"{'é£é™©åŒºåŸŸ':<12} {'é˜ˆå€¼èŒƒå›´':<20} {'ç¾å®³ç‚¹æ•°é‡':<10} {'ç¾å®³ç‚¹æ¯”ä¾‹':<12} {'èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹':<12}")
    print("-" * 80)

    for risk_name, risk_info in results['risk_zones'].items():
        print(f"{risk_name:<12} {risk_info['é˜ˆå€¼èŒƒå›´']:<20} {risk_info['ç¾å®³ç‚¹æ•°é‡']:<10} "
              f"{risk_info['ç¾å®³ç‚¹æ¯”ä¾‹']:<12.1%} {risk_info['èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹']:<12.1%}")

    # ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if 'feature_importance' in results:
        print(f"\nğŸ“Š Top 5é‡è¦ç‰¹å¾:")
        for i, row in results['feature_importance'].head().iterrows():
            print(f"  {row['feature']}: {row['importance']:.4f}")

    print(f"â— ç»“æœä¿å­˜è·¯å¾„: {os.path.abspath(output_dir)}")

    # ç©ºé—´é¢„æµ‹è¾“å‡º
    if Config.EXPORT_TIFF:
        feature_names = df_pos.columns.tolist()
        feature_mapping = {
            feature: os.path.join(Config.BASE_DIR + "entropies", f"{feature}.tif")
            for feature in feature_names
            if os.path.exists(os.path.join(Config.BASE_DIR + "entropies", f"{feature}.tif"))
        }

        processor = RasterProcessor(model, feature_mapping)
        prob_tif_path = os.path.join(output_dir, "susceptibility_probability.tif")
        processor.predict_to_raster(prob_tif_path)
        print(f"âœ… ç©ºé—´æ¦‚ç‡åˆ†å¸ƒå·²ä¿å­˜è‡³: {os.path.abspath(prob_tif_path)}")

        # é£é™©åˆ†åŒº
        risk_thresholds = {
            zone_name: {
                'ä¸‹é™é˜ˆå€¼': float(zone_info['é˜ˆå€¼èŒƒå›´'].split(' - ')[0]),
                'ä¸Šé™é˜ˆå€¼': float(zone_info['é˜ˆå€¼èŒƒå›´'].split(' - ')[1])
            }
            for zone_name, zone_info in results['risk_zones'].items()
        }

        zone_colors = ['red', 'orange', 'yellow', 'lightgreen', 'lightblue']
        zones_tif_path = os.path.join(output_dir, "susceptibility_zones.tif")
        zones = processor.generate_susceptibility_zones(
            prob_tif_path=prob_tif_path,
            risk_thresholds=risk_thresholds,
            output_tif_path=zones_tif_path,
            colors=zone_colors
        )

    end_time = time.time()
    total_time = end_time - start_time

    time_str = f"{total_time:.2f}ç§’"
    print(f"\nğŸ‰ å•åˆ†ç±»SVMç¨‹åºæ‰§è¡Œå®Œæˆï¼æ€»è¿è¡Œæ—¶é—´: {time_str}")
    print("=" * 60)