import time

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import torch
from sklearn.metrics import roc_auc_score
import os
import warnings
import Tools.Regress
from EnergeModel.Tools import Config, DataReader
from EnergeModel.Tools.RasterProcessor import RasterProcessor


warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# ----------------------------
# 2. é€»è¾‘å›å½’æ¨¡å‹ç±»
# ----------------------------
class LogisticRegressionSusceptibilityModel:
    def __init__(self, input_dim: int, random_state: int = 0):
        self.input_dim = input_dim
        self.random_state = random_state
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None

    def build_model(self, **lr_params):
        """æ„å»ºé€»è¾‘å›å½’æ¨¡å‹"""
        default_params = {
            'C': 1.0,  # æ­£åˆ™åŒ–å¼ºåº¦çš„å€’æ•°
            'penalty': 'l2',  # æ­£åˆ™åŒ–ç±»å‹
            'solver': 'sag',  # ä¼˜åŒ–ç®—æ³•
            'max_iter': 50,  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'random_state': self.random_state,
            'verbose': 0
        }

        # æ›´æ–°ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°
        default_params.update(lr_params)

        self.model = LogisticRegression(**default_params)
        return self.model

    def fit(self, X_train, y_train, X_val=None, y_val=None):
        """è®­ç»ƒæ¨¡å‹"""
        # æ•°æ®æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)

        if X_val is not None:
            X_val_scaled = self.scaler.transform(X_val)
            # é€»è¾‘å›å½’æ²¡æœ‰å†…ç½®çš„éªŒè¯é›†è¯„ä¼°ï¼Œä½†æˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨è®¡ç®—
            self.model.fit(X_train_scaled, y_train)
            # è®¡ç®—éªŒè¯é›†AUCï¼ˆç”¨äºç›‘æ§ï¼‰
            val_proba = self.model.predict_proba(X_val_scaled)[:, 1]
            val_auc = roc_auc_score(y_val, val_proba)
            print(f"éªŒè¯é›†AUC: {val_auc:.4f}")
        else:
            self.model.fit(X_train_scaled, y_train)

        return self.model

    def predict_proba(self, X, calibrated=True):
        """é¢„æµ‹æ¦‚ç‡"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")

        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.transform(X)
        return self.model.predict_proba(X_scaled)[:, 1]

    def get_feature_importance(self):
        """è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆç³»æ•°ç»å¯¹å€¼ï¼‰"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        return np.abs(self.model.coef_[0])

    def get_coefficients(self):
        """è·å–å®Œæ•´ç³»æ•°ï¼ˆåŒ…å«æˆªè·é¡¹ï¼‰"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")

        # åˆå¹¶ç³»æ•°å’Œæˆªè·é¡¹
        coefficients = np.concatenate([
            [self.model.intercept_[0]],  # æˆªè·é¡¹
            self.model.coef_[0]  # ç‰¹å¾ç³»æ•°
        ])
        return coefficients

# ----------------------------
# 3. åŸºäºé€»è¾‘å›å½’çš„æ˜“å‘æ€§è¯„ä»·æ¨¡å‹
# ----------------------------
class LogisticRegressionModel:
    def __init__(self, input_dim: int, random_state: int = 0):
        self.input_dim = input_dim
        self.random_state = random_state
        self.lr_model = LogisticRegressionSusceptibilityModel(input_dim, random_state)
        self.feature_names = None

    def forward(self, x):
        """ä¸ºäº†ä¿æŒæ¥å£ä¸€è‡´ï¼Œå®é™…ä¸ç›´æ¥ä½¿ç”¨"""
        pass

    def training_step(self, batch, batch_idx):
        """è®­ç»ƒæ­¥éª¤ - ä¸ºäº†ä¿æŒæ¥å£å…¼å®¹"""
        pass

    def configure_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½® - ä¸ºäº†ä¿æŒæ¥å£å…¼å®¹"""
        pass

    def __call__(self, X):
        """ä½¿æ¨¡å‹å¯¹è±¡å¯è¢«ç›´æ¥è°ƒç”¨"""
        return self.predict_proba(X)

    def predict_proba(self, x, calibrated=True):
        """é¢„æµ‹æ¦‚ç‡"""
        if isinstance(x, torch.Tensor):
            x = x.numpy()
        return self.lr_model.predict_proba(x, calibrated)

    def fit(self, X_pos, X_neg, feature_names):
        """è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹"""
        self.feature_names = feature_names

        # å‡†å¤‡æ•°æ®
        X_train = np.vstack([X_pos, X_neg])
        y_train = np.hstack([np.ones(len(X_pos)), np.zeros(len(X_neg))])



        # æ„å»ºå¹¶è®­ç»ƒæ¨¡å‹
        self.lr_model.build_model()
        self.lr_model.fit(X_train, y_train)

        return self

    def get_feature_importance(self):
        return self.lr_model.get_feature_importance()

    def get_coefficients(self):
        """è·å–å®Œæ•´ç³»æ•°ï¼ˆåŒ…å«æˆªè·é¡¹ï¼‰"""
        # ä»åº•å±‚æ¨¡å‹è·å–ç³»æ•°æ•°ç»„
        coefficients = self.lr_model.get_coefficients()

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        coeff_dict = {
            'intercept': coefficients[0]  # æˆªè·é¡¹
        }

        # æ·»åŠ ç‰¹å¾ç³»æ•°
        if self.feature_names is not None:
            for name, coef in zip(self.feature_names, coefficients[1:]):
                coeff_dict[name] = coef
        else:
            for i, coef in enumerate(coefficients[1:]):
                coeff_dict[f'feature_{i}'] = coef

        return coeff_dict

# ----------------------------
# ä¸»ç¨‹åº
# ----------------------------
if __name__ == "__main__":
    start_time = time.time()
    pos_path = Config.BASE_DIR + Config.POSITIVE+".xlsx"
    neg_path = Config.BASE_DIR + Config.NEG_FILE
    bg_path = Config.BASE_DIR + "mesh3000.xlsx"
    test_path = Config.BASE_DIR + "test.xlsx"
    output_dir = "result/results_logistic_regression"

    # è¿è¡Œè®­ç»ƒè¯„ä¼°æµç¨‹
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    df_pos = DataReader.load_data(pos_path)

    model = LogisticRegressionModel(input_dim=df_pos.shape[1])
    results = Tools.Regress.train_and_evaluate(
        model,
        pos_path=pos_path,
        neg_path=neg_path,
        bg_path=bg_path,
        test_path=test_path,  # ä¼ å…¥æµ‹è¯•é›†è·¯å¾„
        output_dir=output_dir
    )

    print("\nğŸ“Š æ¨¡å‹ç³»æ•°:")
    coefficients = model.get_coefficients()
    for name, value in coefficients.items():
        print(f"  {name:<15}: {value:.6f}")

    # ä¿å­˜ç³»æ•°åˆ°æ–‡ä»¶
    coeff_df = pd.DataFrame.from_dict(coefficients, orient='index', columns=['coefficient'])
    coeff_df.to_excel(os.path.join(output_dir, "model_coefficients.xlsx"))
    print(f"âœ… æ¨¡å‹ç³»æ•°å·²ä¿å­˜è‡³: {os.path.join(output_dir, 'model_coefficients.xlsx')}")

    # æ‰“å°æœ€ç»ˆç»“æœï¼ˆå¢åŠ æµ‹è¯•é›†æŒ‡æ ‡ï¼‰
    print("\nâ­ æœ€ç»ˆè¯„ä¼°ç»“æœ â­")
    print(f"â— AD_AUCåˆ†æ•°: {results['ad_auc_score']:.4f}")
    print(f"â— ROC_AUCåˆ†æ•°: {results['auc_score']:.4f}")
    print(f"â— é¢„æµ‹ç²¾åº¦: {results['train_accuracy']:.4f}")
    print(f"â— é¢„æµ‹å¯†åº¦: {results['train_density']:.4f}")
    print(
        f"â— æ­£æ ·æœ¬æ¦‚ç‡ç»Ÿè®¡ - å‡å€¼: {results['pos_prob_mean']:.3f} Â± {results['pos_prob_std']:.3f} | ä¸­ä½æ•°: {results['pos_median']:.3f}")
    print(
        f"â— è´Ÿæ ·æœ¬æ¦‚ç‡ç»Ÿè®¡ - å‡å€¼: {results['neg_prob_mean']:.3f} Â± {results['neg_prob_std']:.3f} | ä¸­ä½æ•°: {results['neg_median']:.3f}")

    # æ‰“å°æµ‹è¯•é›†ç»“æœ
    if 'test_accuracy' in results:
        print(f"\nğŸ§ª æµ‹è¯•é›†è¯„ä¼°ç»“æœï¼ˆçº¯ç¾å®³æ ·æœ¬ï¼‰:")
        print(f"â— AD_AUCåˆ†æ•°: {results['ad_auc_score_test']:.4f}")
        print(f"â— ROC_AUCåˆ†æ•°: {results['auc_score_test']:.4f}")
        print(f"â— åˆ†ç±»å‡†ç¡®ç‡: {results['test_accuracy']:.2%}")  # ç™¾åˆ†æ¯”æ ¼å¼æ›´ç›´è§‚
        print(f"â— æµ‹è¯•æ ·æœ¬æ•°: {results['test_size']}")

    print(f"\nğŸ“Š é£é™©åŒºåŸŸåˆ†æç»“æœ:")
    print("=" * 80)
    print(f"{'é£é™©åŒºåŸŸ':<12} {'é˜ˆå€¼èŒƒå›´':<20} {'ç¾å®³ç‚¹æ•°é‡':<10} {'ç¾å®³ç‚¹æ¯”ä¾‹':<12} {'èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹':<12}")
    print("-" * 80)

    for risk_name, risk_info in results['risk_zones'].items():
        print(f"{risk_name:<12} {risk_info['é˜ˆå€¼èŒƒå›´']:<20} {risk_info['ç¾å®³ç‚¹æ•°é‡']:<10} "
              f"{risk_info['ç¾å®³ç‚¹æ¯”ä¾‹']:<12.1%} {risk_info['èƒŒæ™¯æ ·æœ¬æ¯”ä¾‹']:<12.1%}")

    print(f"\nğŸ“Š Top 5é‡è¦ç‰¹å¾:")
    for i, row in results['feature_importance'].head().iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")

    print(f"â— ç»“æœä¿å­˜è·¯å¾„: {os.path.abspath(output_dir)}")

    if Config.EXPORT_TIFF:
        feature_names = df_pos.columns.tolist()  # å‡è®¾df_poså·²ä»pos_pathåŠ è½½
        # æ„å»ºç‰¹å¾æ˜ å°„å­—å…¸ï¼ˆè‡ªåŠ¨åŒ¹é…entropiesç›®å½•ä¸‹çš„åŒåtifï¼‰
        feature_mapping = {
            feature: os.path.join(Config.BASE_DIR+"entropies", f"{feature}.tif")
            for feature in feature_names
            if os.path.exists(os.path.join(Config.BASE_DIR+"entropies", f"{feature}.tif"))
        }
        # åˆå§‹åŒ–å¤„ç†å™¨
        processor = RasterProcessor(model, feature_mapping)
        # è¾“å‡ºè·¯å¾„
        prob_tif_path = os.path.join(output_dir, "susceptibility_probability.tif")
        # æ‰§è¡Œé¢„æµ‹
        processor.predict_to_raster(prob_tif_path)
        print(f"âœ… ç©ºé—´æ¦‚ç‡åˆ†å¸ƒå·²ä¿å­˜è‡³: {os.path.abspath(prob_tif_path)}")
        risk_thresholds = {
            zone_name: {
                'ä¸‹é™é˜ˆå€¼': float(zone_info['é˜ˆå€¼èŒƒå›´'].split(' - ')[0]),
                'ä¸Šé™é˜ˆå€¼': float(zone_info['é˜ˆå€¼èŒƒå›´'].split(' - ')[1])
            }
            for zone_name, zone_info in results['risk_zones'].items()
        }

        zone_colors = ['red', 'orange', 'yellow', 'lightgreen', 'lightblue']
        zones_tif_path = os.path.join(output_dir, "susceptibility_zones.tif")
        zones = processor.generate_susceptibility_zones(
            prob_tif_path=prob_tif_path,
            risk_thresholds=risk_thresholds,
            output_tif_path=zones_tif_path,
            colors=zone_colors
        )
    end_time = time.time()
    total_time = end_time - start_time

    # æ ¼å¼åŒ–æ˜¾ç¤ºè¿è¡Œæ—¶é—´
    time_str = f"{total_time:.2f}ç§’"
    print(f"\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼æ€»è¿è¡Œæ—¶é—´: {time_str}")
    print("=" * 60)


